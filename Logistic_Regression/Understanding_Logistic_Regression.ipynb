{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "\n",
        "Logistic Regression is a Classification Algorithm which under the hood uses a simple linear regression model and dumps the output prediction(Continous Values) to a sigmoid funtion that maps the values to the corresponding binary probabilities.\n",
        "\n",
        "So, In a nutshell\n",
        "\n",
        "$$Linear~Regression + Sigmoid ~Function \\Rightarrow Logistic~Regression$$\n",
        "\n",
        "### **Note:**\n",
        "\n",
        "Logistic Regression in its simplest form is a binary classification algorithm and ny extension can be used for multiclass classification using something called as the \"One vs Rest\" approach in which a seperate classifier is calculated for each class.\n",
        "\n",
        "# Math Behind Logistic Regression\n",
        "\n",
        "There is nothing new behind the scene for logistic regression except the inclusion of the sigmoid function, So lest look at the function closely.\n",
        "\n",
        "The Sigmoid Function:\n",
        "\n",
        "$$S(x) = \\frac{1}{1+e^{-z}}$$\n",
        "\n",
        "The function itself is innocent enough there is only variable that needs to be dealt with which is $z$.   \n",
        "Now, what makes the sigmoid function useful is its ability to map given inputs to a space of $(0 - 1)$. This nature of the function can be understood by looking at its curve.\n",
        "\n",
        "Sigmoid Function Curve:\n",
        "\n",
        "![sigmoid](https://ai-master.gitbooks.io/logistic-regression/content/assets/sigmoid_function.png)\n",
        "\n",
        "So, the sigmoid function takes any real number, and returns a numbers in the space $(0-1)$. Because of this, We can combine the sigmoid function at the end of the linear regression and instead of the continous values we can obtain the corresponding sigmoid's output that can be interpreted as probabilities in a binary classification problem and we can use these to make stochastic predictions.\n",
        "\n",
        "So, Using a general linear regression model:\n",
        "\n",
        "$$y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\dots +\\beta_kx_k$$\n",
        "\n",
        "The Logistic Regression Model will become:\n",
        "\n",
        "$$P(y = 1|x) = \\frac{1}{1 + e^{-(\\beta_0 + \\beta_1x_1+ \\dots +\\beta_kx_k)}}$$\n",
        "\n",
        "Since, the values of $\\beta$ vector or the coefficients of the linear regression model will be different for every problem therefore, the shape of sigmoid function will also be different for every problem but the function will always retain its general shape and properties.\n",
        "\n",
        "### **Bonus:**\n",
        "\n",
        "Since, the logistic regression only introduces the sigmoid function at end of the linear regression pipeline we can use any algorithm for the linear regression and convert it to it's corresponding logistic regression algorithm. For example lasso logistic regression or least squares logistic regression."
      ],
      "metadata": {
        "id": "7qkw7GGieMl-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementing Logistic Regression\n",
        "\n",
        "For this implementation, A Gradient descent linear regression will be used and converted to a Gradient Descent Logistic Regression"
      ],
      "metadata": {
        "id": "gsVk9D7ckBjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First we need a sample dataset on which we can test our algorithms\n",
        "#Using sklearn to create a random binary classification problem\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X,y = make_classification(n_samples=200,\n",
        "                      n_features=12, \n",
        "                      n_classes=2, \n",
        "                      random_state=42)\n",
        "\n",
        "#Splitting the dataset into test and training sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "#looking at the generated Data\n",
        "X_train[:5,:] #First Five rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdIb8Jg2kAF_",
        "outputId": "c8e56003-e7f4-48e0-8c51-ec6b314c1ac4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-1.18759842,  0.30982071, -1.08801577,  1.58463429,  2.14514913,\n",
              "         1.24774207,  0.27899416, -0.96510344, -0.67349062, -0.29494968,\n",
              "        -0.83534705,  0.81794088],\n",
              "       [-0.13744851,  0.95287455, -0.35988191,  0.77000611,  1.37365855,\n",
              "         0.67787532, -1.8306329 ,  0.24554453, -0.65407568, -2.70323229,\n",
              "         0.5112026 ,  0.19476642],\n",
              "       [-1.11057585,  1.75227044,  1.18137586, -2.34174533, -0.77781669,\n",
              "        -2.07339023, -0.37144087, -0.37892304, -0.34268759,  1.24608519,\n",
              "        -1.40751169, -0.69666772],\n",
              "       [-0.43449623, -0.30917212,  0.47282467, -1.28206838, -0.46227529,\n",
              "         0.02975614, -0.51604473, -0.94377212,  0.93828381,  0.02831838,\n",
              "         0.09612078, -0.17253989],\n",
              "       [ 0.77836108, -0.55118572, -0.18053048,  0.77127784,  0.59252695,\n",
              "         2.00609289,  1.20836623,  1.00760453,  2.06150358,  1.54210995,\n",
              "         1.02406253, -0.02097391]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the Gradient Descent Logistic Regression Algorithm\n",
        "import numpy as np\n",
        "\n",
        "class MyLogisticRegression():\n",
        "\n",
        "  def __init__(self, n_iterations=1000, learning_rate=0.001):\n",
        "\n",
        "    self.weights = None #Initializing weights vector\n",
        "    self.intercept = None #Initializing intercept\n",
        "    self.n_iterations = n_iterations #setting number of iterations\n",
        "    self.lr = learning_rate #setting learning rate\n",
        "\n",
        "  def _Gradient_Descent(self, n_samples, X, y_probs, y_act):\n",
        "    \n",
        "    #Compute Gradient\n",
        "    self._Dw = (-1) * (1/n_samples) * np.dot(X.transpose(), (y_act - y_probs))\n",
        "    self._Di = (-1) * (1/n_samples) * np.sum(y_act - y_probs)\n",
        "\n",
        "    #Update Model Parameters\n",
        "    self.weights = self.weights - (self.lr * self._Dw)\n",
        "    self.intercept = self.intercept - (self.lr * self._Di)\n",
        "\n",
        "  def _sigmoid(self, y_cont): #A method for the sigmoid function\n",
        "\n",
        "    return 1 / (1 + np.exp(-y_cont))\n",
        "  \n",
        "  def fit(self, X, y):\n",
        "\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    #Initializing Parameters\n",
        "    self.weights = np.zeros(n_features)\n",
        "    self.intercept = 0\n",
        "\n",
        "    for _ in range(self.n_iterations):\n",
        "\n",
        "      #Calculating Continous Prediction(Regression)\n",
        "      y_cont = self.intercept + X.dot(self.weights)\n",
        "\n",
        "      #Converting the continous prediction to class probabilities Using Sigmoid Function\n",
        "      y_probs = self._sigmoid(y_cont)\n",
        "\n",
        "      #Gradient Descent\n",
        "      self._Gradient_Descent(n_samples, X, y_probs, y)\n",
        "\n",
        "  def predict(self, x, threshold=0.5):\n",
        "\n",
        "    if type(x) != 'numpy.ndarray':\n",
        "      x = np.array(x)\n",
        "\n",
        "    y_cont = self.intercept + x.dot(self.weights)\n",
        "    y_probs = self._sigmoid(y_cont)\n",
        "    y_preds = [1 if y_prob > threshold else 0 for y_prob in y_probs]\n",
        "    return y_preds\n"
      ],
      "metadata": {
        "id": "dCnLpRrVkkJ9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Now, we can test our Logistic Regression Algorithm\n",
        "model = MyLogisticRegression(n_iterations=1000, learning_rate=0.005) #Creating an instances\n",
        "model.fit(X_train,y_train) #Fitting the model\n",
        "\n",
        "#Lets see the weights and the intercept\n",
        "print('The Calculated Model:')\n",
        "print('The Coefficients = {}'.format(model.weights.round(4)))\n",
        "print('The Intercept {:.4f}'.format(model.intercept))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rccnrSNclza0",
        "outputId": "d322d4f3-a5af-41b0-f5c1-2f7459111f14"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Calculated Model:\n",
            "The Coefficients = [-0.0384  0.1237  0.1698  0.1423  0.0547  0.1277  0.1024  1.0456  0.0565\n",
            "  0.0339 -0.011  -0.2477]\n",
            "The Intercept -0.0483\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Since, this is a classification problem the weights of the regression will not\n",
        "#be very useful but we can calculate the accuracy of model\n",
        "\n",
        "#Helper function to calculate accuracy\n",
        "def accuracy(y_true,y_pred):\n",
        "  accuracy = np.sum(y_true == y_pred)/len(y_true)\n",
        "  return accuracy\n",
        "\n",
        "#Getting predictions\n",
        "y_test_preds = model.predict(X_test)\n",
        "\n",
        "#Evaluating Performance on Test set\n",
        "acc = accuracy(y_test,y_test_preds)\n",
        "print('The Accuracy gained by our Algorithm on Test Set = {:.2f}%'.format(acc*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9WVgtX8mDKa",
        "outputId": "43c935e3-848b-4dd6-dec1-f6e071110832"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Accuracy gained by our Algorithm on Test Set = 81.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The algorithm maganged to achieve >80% Accuracy withoud any regularization\n",
        "#Lets look at 10 random predictions from the test data\n",
        "\n",
        "choices = np.random.choice(60, size=10, replace=False)\n",
        "batch_test = X_test[choices, :]\n",
        "y_actual = y_test[choices]\n",
        "y_actual = y_actual.reshape(-1,1)\n",
        "\n",
        "#Extracting predictions\n",
        "y_preds = np.array(model.predict(batch_test))\n",
        "\n",
        "#Making a dataframe of actual and predicted results\n",
        "y_preds = y_preds.reshape(-1,1)\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(np.concatenate((y_actual,y_preds), axis = 1), columns = ['Actual', 'Predicted'])\n",
        "df['Remark'] = 'Incorrect Prediction'\n",
        "df.loc[df['Actual'] == df['Predicted'], 'Remark'] = 'Correct Prediction'\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        },
        "id": "Lzl7JFcPs9Mt",
        "outputId": "28103c3f-c251-447c-c9f8-f0012ac8f97d"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cc96bee0-a272-47a4-8474-6f20623ee04c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Actual</th>\n",
              "      <th>Predicted</th>\n",
              "      <th>Remark</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Correct Prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Correct Prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Correct Prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Correct Prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Correct Prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Correct Prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Incorrect Prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Correct Prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Correct Prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>Incorrect Prediction</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cc96bee0-a272-47a4-8474-6f20623ee04c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cc96bee0-a272-47a4-8474-6f20623ee04c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cc96bee0-a272-47a4-8474-6f20623ee04c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Actual  Predicted                Remark\n",
              "0       0          0    Correct Prediction\n",
              "1       0          0    Correct Prediction\n",
              "2       0          0    Correct Prediction\n",
              "3       1          1    Correct Prediction\n",
              "4       1          1    Correct Prediction\n",
              "5       0          0    Correct Prediction\n",
              "6       1          0  Incorrect Prediction\n",
              "7       0          0    Correct Prediction\n",
              "8       0          0    Correct Prediction\n",
              "9       1          0  Incorrect Prediction"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    }
  ]
}